# IfAI v0.3.3 发布说明

## 概览
**若爱 (IfAI) v0.3.3** 是一个专注于**智能化与模块化**的功能版本。本次更新引入了全新的**工具分类系统**，通过三层智能分类机制自动将用户请求路由到最合适的工具，大幅提升了 AI 交互的准确性和效率。

同时，我们对 Agent 系统进行了深度模块化重构，提取了工具注册表、事件监听器、去重器等核心服务模块，为后续功能扩展奠定了坚实的架构基础。

---

## 🚀 核心更新

### 🤖 工具分类系统 (Tool Classification System)

**问题背景**
在之前的版本中，所有 AI 请求都需要通过 LLM 进行语义判断，然后由 Agent 系统决定调用哪个工具。这种方式虽然灵活，但存在以下问题：
- **延迟较高**：每次请求都需要调用 LLM 进行分类
- **成本浪费**：简单命令（如 `/git status`）也需要 LLM 判断
- **准确性不稳定**：LLM 的分类结果可能因模型不同而波动

**解决方案**
v0.3.3 引入了**三层智能分类机制**：

```
用户输入 → Layer 1: 精确匹配 → Layer 2: 规则引擎 → Layer 3: LLM 智能判断
            ↓ 直接执行          ↓ 关键词匹配         ↓ 语义理解
```

#### Layer 1: 精确匹配 (Exact Match)
- 直接识别命令格式：`/git status`、`/npm install`、`/cargo build`
- 零延迟，立即执行
- 覆盖 20+ 常用命令

#### Layer 2: 规则引擎 (Rule-based Engine)
- 基于关键词模式识别
- 支持 6 大工具类别：文件操作、代码生成、代码分析、终端命令、搜索操作、AI 对话
- 使用正则表达式和启发式规则
- 准确率 > 95%

#### Layer 3: LLM Fallback
- 处理复杂语义和模糊请求
- 仅在 Layer 1 和 2 无法确定时启用
- 支持 GPT-4、Claude 等高性能模型

**技术亮点**
- ✅ **零配置**：用户无需手动选择工具，系统自动判断
- ✅ **高性能**：约 70% 的请求在 Layer 1-2 完成，无需 LLM 调用
- ✅ **可扩展**：基于工具注册表设计，新增工具只需注册即可
- ✅ **完整测试**：70+ 单元测试覆盖所有分类规则

---

### 🔧 Agent 系统模块化重构

**重构目标**
将 Agent 系统从单体架构拆分为多个独立的服务模块，提升代码的可维护性、可测试性和可扩展性。

**核心模块**

#### 1. 工具注册表 (ToolRegistry)
- **职责**：统一管理所有内置工具的定义、注册和查找
- **优势**：新增工具时只需调用注册 API，无需修改核心代码
- **支持工具**：bash、agent_read_file、agent_write_file、agent_list_dir 等

#### 2. 事件监听器 (AgentListeners)
- **职责**：标准化 Agent 事件处理（进度、工具调用、完成、错误）
- **优势**：统一的事件接口，便于前端展示和日志记录
- **事件类型**：progress、tool_call、finish、error

#### 3. 去重器 (ToolCallDeduplicator)
- **职责**：防止重复执行相同的工具调用
- **优势**：避免资源浪费，提升系统稳定性
- **机制**：基于工具名称和参数的哈希去重

#### 4. 格式化器 (Formatters)
- **职责**：提供多种输出格式（Task Tree、Markdown、增量解析）
- **优势**：满足不同场景的展示需求
- **格式类型**：
  - Task Tree：可视化任务树结构
  - Markdown：标准 Markdown 格式
  - 增量解析：实时更新任务进度

---

### 🔌 自定义提供商增强

**问题背景**
用户反馈配置 NVIDIA 等自定义提供商时出现 404 错误，无法正常调用 API。

**根本原因**
1. **字段命名不匹配**：前端使用 camelCase（apiKey、baseUrl），后端 Rust 使用 snake_case（api_key、base_url）
2. **模型列表为空**：自定义预设的默认模型列表为空数组，导致 currentModel 为空字符串

**修复内容**
- ✅ 修复字段映射问题，确保前后端字段命名一致
- ✅ 添加示例模型列表（z-ai/glm4.7、nv-tmp、gpt-4o-mini 等）
- ✅ 添加模型为空时的验证和提示
- ✅ 修复商业版 ifainew-core 中的相关逻辑

**支持的提供商**
- NVIDIA（默认模型：z-ai/glm4.7）
- OpenAI（默认模型：gpt-4o-mini）
- Anthropic（默认模型：claude-3-5-sonnet-20241022）
- 其他 OpenAI 兼容 API

---

### 📁 目录列表优化

**改进内容**
- 🔍 **智能过滤**：自动隐藏 `.git`、`node_modules`、`target` 等系统目录
- 📊 **统计信息**：显示文件和目录的数量（如 "5 files, 3 directories"）
- 📁 **更清晰的视图**：专注于项目代码，减少噪音

**技术实现**
- 在 `agent_list_dir` 工具中添加目录过滤逻辑
- 使用正则表达式匹配系统目录名称
- 在返回结果中添加统计字段

---

## 🧪 测试与验证

本次发布经过了严格的自动化测试验证：

### 单元测试
- **工具分类测试**：70+ 测试用例覆盖所有分类规则
- **分类准确率**：Layer 1 精确匹配 100%，Layer 2 规则引擎 >95%
- **模块化测试**：每个服务模块都有独立的单元测试

### E2E 测试
- **工具分类基线测试**：建立测试基线，防止功能回归
- **Tauri 模式检测**：避免在非 Tauri 环境执行特定测试
- **回归测试标记**：标识需要验证的关键测试脚本

### 性能测试
- **分类延迟**：Layer 1 < 1ms，Layer 2 < 10ms
- **LLM 调用减少**：约 70% 的请求无需 LLM 参与
- **内存占用**：模块化架构后，内存占用无明显增加

---

## 📦 如何更新

### 自动更新
如果您已安装 IfAI，启动应用后将自动检测到新版本。点击更新提示即可完成升级。

### 手动下载
您可以前往 [GitHub Releases](https://github.com/peterfei/ifai/releases/tag/v0.3.3) 页面下载对应平台的安装包：
- **Windows**: `IfAI_0.3.3_x64_en-US.msi`
- **macOS (Apple Silicon)**: `IfAI_0.3.3_aarch64.dmg`
- **macOS (Intel)**: `IfAI_0.3.3_x64.dmg`
- **Linux**: `IfAI_0.3.3_amd64.AppImage`

---

## 🔄 升级指南

### 从 v0.3.2 升级

1. **下载新版本**并安装
2. **验证功能**：尝试使用工具分类系统
   - 输入 `/git status` 查看精确匹配
   - 输入 "分析代码" 查看规则引擎
   - 输入复杂问题查看 LLM fallback
3. **重新配置自定义提供商**（如有 NVIDIA 等提供商）
   - 删除旧的提供商配置
   - 重新添加，新的配置会自动填充模型列表

### 配置变更
- **工具分类系统**：自动生效，无需额外配置
- **自定义提供商**：如遇到 404 错误，重新添加即可
- **其他功能**：无需任何配置变更

---

## 📝 已知问题

- 无重大已知问题

---

## 🙏 致谢

感谢所有参与测试和反馈的用户！

特别感谢：
- @beta-testers - 工具分类系统测试和反馈
- @contributors - NVIDIA 提供商问题排查

---

## 🔮 下个版本预告 (v0.3.4)

- 更多工具分类规则优化
- Agent 任务拆解增强
- 性能监控和统计面板
- 更多自定义提供商预设

---

## 📝 变更日志

详细变更记录请参阅 [CHANGELOG.md](../CHANGELOG.md)。

---

<div align="center">
  <p>⭐ 如果这个项目对你有帮助，请给个 Star！</p>
  <p>🐛 发现问题？请提交 <a href="https://github.com/peterfei/ifai/issues">Issue</a></p>
</div>
