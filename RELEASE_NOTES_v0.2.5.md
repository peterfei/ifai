# IfAI v0.2.5 Release Notes - 混合智能与 Token 极致优化

## 概览 (Overview)

IfAI v0.2.5 (2026-01-03) 是一个以**“成本与效率”**为核心的重大更新。通过自主研发的智能调度算法，我们实现了云端算力与本地算力的完美平衡，大幅降低了用户的 Token 消耗。

## 🚀 本次更新亮点

### 💎 极致 Token 节省：智能调度算法
- **按需分发**：系统会根据任务类型（补全、搜索、推理、改写）自动计算所需的模型强度。
- **本地优先策略**：高频、短小的补全请求和基础查询将 100% 由本地模型承载，**预计可为活跃开发者节省 70% 以上的云端 Token 费用**。
- **上下文压缩**：在切换至云端模型时，调度器会智能精简发送的上下文，只带走最关键的信息，拒绝无效 Token 浪费。

### 🛠️ Agent 工具调用本地化 (Local-First Agent)
- **自有 0.5B 模型驱动**：我们针对 `read_file`、`list_dir`、`grep` 等 Agent 工具调用场景，对自主微调的 0.5B 模型进行了专项强化。
- **离线执行**：现在，Agent 的**思考路径**和**工具选择**过程完全在本地完成。这意味着 Agent 在探索代码库、寻找文件时，不再产生任何云端费用。
- **亚秒级反馈**：本地模型消除了云端 API 的往返延迟（RTT），Agent 连续执行工具的速度提升了 3 倍以上。

### 🔒 自主微调 0.5B 本地模型
- **专精定位**：不同于通用大模型，我们的本地 0.5B 模型专注于**代码补全 (FIM)** 和 **工具指令生成**。
- **硬件友好**：模型文件仅约 600MB，显存占用极低，在 8GB 内存设备上也能实现毫秒级响应。
- **注意**：本地模型目前不适用于长篇的代码生成或深度的逻辑解释，这类任务将由智能路由器自动引导至云端。

## ✨ 其他改进
- **冷启动优化**：大幅缩短了本地模型的首次加载时间。
- **UI 增强**：在聊天窗口明确标识当前任务是由“本地”还是“云端”处理，费用去向一目了然。

---

## 📦 如何获取
请访问 [GitHub Releases](https://github.com/peterfei/ifai/releases) 下载 v0.2.5 安装包。