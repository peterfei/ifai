// Token è®¡æ•°æ¨¡å— - v0.2.6 æ–°å¢
// æ”¯æŒ tiktokenï¼ˆäº‘ç«¯æ¨¡å‹ï¼‰

use tiktoken_rs::{cl100k_base, o200k_base, p50k_base, get_bpe_from_model};

/// Token è®¡æ•°ç»“æœ
#[derive(serde::Serialize, serde::Deserialize, Debug)]
pub struct TokenCountResult {
    pub count: usize,
    pub encoding: String,
}

/// ä¸º OpenAI æ¨¡å‹è®¡æ•° Token
pub fn count_tokens_openai(text: &str, model: &str) -> usize {
    // æ ¹æ®æ¨¡å‹é€‰æ‹©ç¼–ç å™¨
    let bpe = get_bpe_from_model(model);

    match bpe {
        Ok(bpe) => {
            bpe.encode_with_special_tokens(text).len()
        }
        Err(_) => {
            // ğŸ”¥ å®‰å…¨å›é€€ï¼šä¸å†ä½¿ç”¨ unwrap()ï¼Œå¦‚æœ cl100k_base ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨å­—ç¬¦ä¼°ç®—
            match cl100k_base() {
                Ok(fallback) => fallback.encode_with_special_tokens(text).len(),
                Err(_) => estimate_tokens(text)
            }
        }
    }
}

/// ç®€åŒ–çš„ Token è®¡æ•°ï¼ˆç”¨äºå¿«é€Ÿä¼°ç®—ï¼‰
/// åŸºäºå­—ç¬¦æ•°å’Œå¸¸è§ Token æ¯”ä¾‹
pub fn estimate_tokens(text: &str) -> usize {
    // è‹±æ–‡å¤§çº¦ 4 å­—ç¬¦ = 1 Token
    // ä¸­æ–‡å¤§çº¦ 1.5-2 å­—ç¬¦ = 1 Token
    // è¿™é‡Œä½¿ç”¨æ··åˆä¼°ç®—
    let chinese_chars = text.chars().filter(|c| {
        let cp = *c as u32;
        (0x4E00..=0x9FFF).contains(&cp) || // CJK ç»Ÿä¸€æ±‰å­—
        (0x3400..=0x4DBF).contains(&cp) || // CJK æ‰©å±• A
        (0x20000..=0x2A6DF).contains(&cp) // CJK æ‰©å±• B
    }).count();

    let other_chars = text.len() - chinese_chars;

    (chinese_chars / 2) + (other_chars / 4)
}

/// æ‰¹é‡è®¡æ•°å¤šä¸ªæ–‡æœ¬ç‰‡æ®µçš„ Token
pub fn count_tokens_batch_internal(texts: &[String], model: &str) -> Vec<usize> {
    let bpe = get_bpe_from_model(model);

    match bpe {
        Ok(bpe) => {
            texts.iter()
                .map(|text| bpe.encode_with_special_tokens(text).len())
                .collect()
        }
        Err(_) => {
            // ğŸ”¥ å®‰å…¨å›é€€ï¼šä¸å†ä½¿ç”¨ unwrap()
            let fallback_bpe = cl100k_base().ok();
            texts.iter()
                .map(|text| {
                    match &fallback_bpe {
                        Some(f) => f.encode_with_special_tokens(text).len(),
                        None => estimate_tokens(text)
                    }
                })
                .collect()
        }
    }
}

// ============== Tauri å‘½ä»¤ ==============

/// è®¡æ•°å•ä¸ªæ–‡æœ¬çš„ Token æ•°é‡
///
/// # å‚æ•°
/// - `text`: è¦è®¡æ•°çš„æ–‡æœ¬
/// - `model`: æ¨¡å‹åç§°ï¼ˆç”¨äºé€‰æ‹©ç¼–ç å™¨ï¼‰
///
/// # è¿”å›
/// è¿”å› Token æ•°é‡
#[tauri::command]
pub fn count_tokens(text: String, model: String) -> usize {
    count_tokens_openai(&text, &model)
}

/// æ‰¹é‡è®¡æ•°å¤šä¸ªæ–‡æœ¬çš„ Token æ•°é‡
///
/// # å‚æ•°
/// - `texts`: æ–‡æœ¬æ•°ç»„
/// - `model`: æ¨¡å‹åç§°
///
/// # è¿”å›
/// è¿”å›æ¯ä¸ªæ–‡æœ¬çš„ Token æ•°é‡æ•°ç»„
#[tauri::command]
pub fn count_tokens_batch(texts: Vec<String>, model: String) -> Vec<usize> {
    count_tokens_batch_internal(&texts, &model)
}

/// å¿«é€Ÿä¼°ç®— Token æ•°é‡ï¼ˆä¸ä½¿ç”¨ tiktokenï¼ŒåŸºäºå­—ç¬¦æ•°ï¼‰
///
/// # å‚æ•°
/// - `text`: è¦ä¼°ç®—çš„æ–‡æœ¬
///
/// # è¿”å›
/// è¿”å›ä¼°ç®—çš„ Token æ•°é‡
#[tauri::command]
pub fn estimate_tokens_cmd(text: String) -> usize {
    estimate_tokens(&text)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_count_tokens_english() {
        let text = "Hello, world!";
        let count = count_tokens_openai(text, "gpt-4");
        assert!(count > 0);
        println!("'{}' has {} tokens (gpt-4)", text, count);
    }

    #[test]
    fn test_count_tokens_chinese() {
        let text = "ä½ å¥½ï¼Œä¸–ç•Œï¼";
        let count = count_tokens_openai(text, "gpt-4");
        assert!(count > 0);
        println!("'{}' has {} tokens (gpt-4)", text, count);
    }

    #[test]
    fn test_estimate_tokens() {
        let text = "Hello world ä½ å¥½ä¸–ç•Œ";
        let estimate = estimate_tokens(text);
        assert!(estimate > 0);
        println!("'{}' estimated {} tokens", text, estimate);
    }

    #[test]
    fn test_batch_count() {
        let texts = vec![
            "Hello".to_string(),
            "World".to_string(),
            "Test".to_string(),
        ];
        let counts = count_tokens_batch_internal(&texts, "gpt-4");
        assert_eq!(counts.len(), 3);
        println!("Batch counts: {:?}", counts);
    }
}
